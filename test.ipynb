{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type int64 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m config \u001b[38;5;241m=\u001b[39m Config()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Preprocess the dataset for classification (CNN)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m preprocessed_classification \u001b[38;5;241m=\u001b[39m preprocess_aachen_dataset(\n\u001b[1;32m     16\u001b[0m     data_path\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdata_path,\n\u001b[1;32m     17\u001b[0m     test_cell_count\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtest_cell_count,\n\u001b[1;32m     18\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[1;32m     19\u001b[0m     log_transform\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlog_transform,\n\u001b[1;32m     20\u001b[0m     classification\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Explore classification (CNN) output\u001b[39;00m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Preprocess the dataset for regression (LSTM)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m preprocessed_regression \u001b[38;5;241m=\u001b[39m preprocess_aachen_dataset(\n\u001b[1;32m     25\u001b[0m     data_path\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdata_path,\n\u001b[1;32m     26\u001b[0m     test_cell_count\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtest_cell_count,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     classification\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# Explore regression (LSTM) output\u001b[39;00m\n\u001b[1;32m     30\u001b[0m )\n",
      "File \u001b[0;32m~/Student/Master kode/Master_Herstad-Gjerdingen/src/preprocessing.py:275\u001b[0m, in \u001b[0;36mpreprocess_aachen_dataset\u001b[0;34m(data_path, test_cell_count, random_state, log_transform, classification)\u001b[0m\n\u001b[1;32m    264\u001b[0m metadata \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    265\u001b[0m     model_type: {\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_max\u001b[39m\u001b[38;5;124m\"\u001b[39m: y_max,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     }\n\u001b[1;32m    273\u001b[0m }\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meol_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 275\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(metadata, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m preprocessed_data\n",
      "File \u001b[0;32m/opt/miniconda3/envs/D2D_env/lib/python3.11/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/D2D_env/lib/python3.11/json/encoder.py:432\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/D2D_env/lib/python3.11/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/D2D_env/lib/python3.11/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/D2D_env/lib/python3.11/json/encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m _default(o)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/D2D_env/lib/python3.11/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type int64 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Import from src/ and config/\n",
    "from src.preprocessing import preprocess_aachen_dataset\n",
    "from config.defaults import Config\n",
    "\n",
    "# Load the default configuration\n",
    "config = Config()\n",
    "\n",
    "# Preprocess the dataset for classification (CNN)\n",
    "preprocessed_classification = preprocess_aachen_dataset(\n",
    "    data_path=config.data_path,\n",
    "    test_cell_count=config.test_cell_count,\n",
    "    random_state=config.random_state,\n",
    "    log_transform=config.log_transform,\n",
    "    classification=True  # Explore classification (CNN) output\n",
    ")\n",
    "\n",
    "# Preprocess the dataset for regression (LSTM)\n",
    "preprocessed_regression = preprocess_aachen_dataset(\n",
    "    data_path=config.data_path,\n",
    "    test_cell_count=config.test_cell_count,\n",
    "    random_state=config.random_state,\n",
    "    log_transform=config.log_transform,\n",
    "    classification=False  # Explore regression (LSTM) output\n",
    ")\n",
    "\n",
    "# Explore classification (CNN) output\n",
    "print(\"# Classification (CNN) Output Exploration\")\n",
    "print(\"X_train shape:\", preprocessed_classification[\"X_train\"].shape)  # Expected: (n_samples, 120, 1)\n",
    "print(\"X_val shape:\", preprocessed_classification[\"X_val\"].shape)      # Expected: (n_samples, 120, 1)\n",
    "print(\"X_test shape:\", preprocessed_classification[\"X_test\"].shape)    # Expected: (n_samples, 120, 1)\n",
    "print(\"y_train shape:\", preprocessed_classification[\"y_train\"].shape)  # Expected: (n_samples, 7) for one-hot encoding\n",
    "print(\"y_max:\", preprocessed_classification[\"y_max\"])                 # Maximum RUL for scaling\n",
    "print(\"label_mapping:\", preprocessed_classification[\"label_mapping\"])  # RUL bin mappings\n",
    "print(\"max_sequence_length:\", preprocessed_classification[\"max_sequence_length\"])  # Should be 120 for classification\n",
    "print(\"Sample X_train[0]:\\n\", preprocessed_classification[\"X_train\"][0])  # First sequence\n",
    "print(\"Sample y_train[0]:\\n\", preprocessed_classification[\"y_train\"][0])  # First one-hot label\n",
    "\n",
    "# Explore regression (LSTM) output\n",
    "print(\"\\n# Regression (LSTM) Output Exploration\")\n",
    "print(\"X_train shape:\", preprocessed_regression[\"X_train\"].shape)     # Expected: (n_samples, max_seq_len, 1)\n",
    "print(\"X_val shape:\", preprocessed_regression[\"X_val\"].shape)         # Expected: (n_samples, max_seq_len, 1)\n",
    "print(\"X_test shape:\", preprocessed_regression[\"X_test\"].shape)       # Expected: (n_samples, max_seq_len, 1)\n",
    "print(\"y_train shape:\", preprocessed_regression[\"y_train\"].shape)     # Expected: (n_samples,)\n",
    "print(\"y_max:\", preprocessed_regression[\"y_max\"])                     # Maximum RUL for scaling\n",
    "print(\"max_sequence_length:\", preprocessed_regression[\"max_sequence_length\"])  # Maximum sequence length\n",
    "print(\"Sample X_train[0] shape:\", preprocessed_regression[\"X_train\"][0].shape)  # First sequence dimensions\n",
    "print(\"Sample y_train[0]:\", preprocessed_regression[\"y_train\"][0])     # First normalized RUL\n",
    "\n",
    "# Additional exploration: Class distribution for classification (if applicable)\n",
    "if preprocessed_classification[\"label_mapping\"]:\n",
    "    y_train_classes = np.argmax(preprocessed_classification[\"y_train\"], axis=1)\n",
    "    print(\"\\nClassification Class Distribution (Training):\\n\", pd.Series(y_train_classes).value_counts())\n",
    "\n",
    "# Additional exploration: RUL statistics for regression\n",
    "print(\"\\nRegression RUL Statistics (Training):\")\n",
    "print(\"Mean RUL (normalized):\", np.mean(preprocessed_regression[\"y_train\"]))\n",
    "print(\"Std RUL (normalized):\", np.std(preprocessed_regression[\"y_train\"]))\n",
    "print(\"Min RUL (normalized):\", np.min(preprocessed_regression[\"y_train\"]))\n",
    "print(\"Max RUL (normalized):\", np.max(preprocessed_regression[\"y_train\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (D2D_env)",
   "language": "python",
   "name": "d2d_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
