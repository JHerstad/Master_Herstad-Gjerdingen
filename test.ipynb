{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprossessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from src/ and config/\n",
    "from src.preprocessing import preprocess_aachen_dataset\n",
    "from config.defaults import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Classification (CNN) Output Exploration\n",
      "X_train shape: (4513, 120, 1)\n",
      "X_val shape: (1129, 120, 1)\n",
      "X_test shape: (391, 120, 1)\n",
      "y_train shape: (4513, 7)\n",
      "y_max: 1000\n",
      "label_mapping: {'0-200': 0, '200-300': 1, '300-400': 2, '400-500': 3, '500-600': 4, '600-700': 5, '700+': 6}\n",
      "max_sequence_length: 120\n",
      "Sample X_train[0]:\n",
      " [[0.7065943 ]\n",
      " [0.70419202]\n",
      " [0.70179161]\n",
      " [0.69939201]\n",
      " [0.69699363]\n",
      " [0.69459688]\n",
      " [0.69220215]\n",
      " [0.68980987]\n",
      " [0.68742044]\n",
      " [0.68503425]\n",
      " [0.68265173]\n",
      " [0.68027327]\n",
      " [0.67789927]\n",
      " [0.67553016]\n",
      " [0.67316633]\n",
      " [0.67080819]\n",
      " [0.66845615]\n",
      " [0.66611061]\n",
      " [0.66377198]\n",
      " [0.66144066]\n",
      " [0.65911706]\n",
      " [0.6568016 ]\n",
      " [0.65449467]\n",
      " [0.65219668]\n",
      " [0.64990803]\n",
      " [0.64762914]\n",
      " [0.64536041]\n",
      " [0.64310225]\n",
      " [0.64085506]\n",
      " [0.63861924]\n",
      " [0.63639522]\n",
      " [0.63418338]\n",
      " [0.63198415]\n",
      " [0.62980354]\n",
      " [0.6276634 ]\n",
      " [0.6255628 ]\n",
      " [0.62349819]\n",
      " [0.62146602]\n",
      " [0.61946276]\n",
      " [0.61748485]\n",
      " [0.61552876]\n",
      " [0.61359094]\n",
      " [0.61166785]\n",
      " [0.60975594]\n",
      " [0.60785167]\n",
      " [0.60595149]\n",
      " [0.60405187]\n",
      " [0.60214925]\n",
      " [0.6002401 ]\n",
      " [0.59832087]\n",
      " [0.59638802]\n",
      " [0.594438  ]\n",
      " [0.59246726]\n",
      " [0.59047228]\n",
      " [0.58844949]\n",
      " [0.58639536]\n",
      " [0.58430635]\n",
      " [0.58217891]\n",
      " [0.58000949]\n",
      " [0.57779456]\n",
      " [0.57553056]\n",
      " [0.57321396]\n",
      " [0.57084121]\n",
      " [0.56840877]\n",
      " [0.56591309]\n",
      " [0.56336052]\n",
      " [0.56075984]\n",
      " [0.55811123]\n",
      " [0.55541484]\n",
      " [0.55267082]\n",
      " [0.54987933]\n",
      " [0.54704052]\n",
      " [0.54415455]\n",
      " [0.54122158]\n",
      " [0.53824177]\n",
      " [0.53521526]\n",
      " [0.53214222]\n",
      " [0.5290228 ]\n",
      " [0.52585715]\n",
      " [0.52264544]\n",
      " [0.51938782]\n",
      " [0.51608444]\n",
      " [0.51273547]\n",
      " [0.50934105]\n",
      " [0.50590134]\n",
      " [0.50241651]\n",
      " [0.49888669]\n",
      " [0.49531206]\n",
      " [0.49169277]\n",
      " [0.48802897]\n",
      " [0.48432082]\n",
      " [0.48056847]\n",
      " [0.47677209]\n",
      " [0.47293182]\n",
      " [0.46904783]\n",
      " [0.46512026]\n",
      " [0.46115021]\n",
      " [0.45714516]\n",
      " [0.45310376]\n",
      " [0.44902232]\n",
      " [0.44489715]\n",
      " [0.44072459]\n",
      " [0.43650095]\n",
      " [0.43222255]\n",
      " [0.4278857 ]\n",
      " [0.42348673]\n",
      " [0.41902196]\n",
      " [0.4144877 ]\n",
      " [0.40988027]\n",
      " [0.40519601]\n",
      " [0.40043121]\n",
      " [0.3955822 ]\n",
      " [0.39064531]\n",
      " [0.38561685]\n",
      " [0.38049313]\n",
      " [0.37527049]\n",
      " [0.36994523]\n",
      " [0.36451368]\n",
      " [0.35897216]\n",
      " [0.35331699]]\n",
      "Sample y_train[0]:\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      "\n",
      "# Regression (LSTM) Output Exploration\n",
      "X_train shape: (4513, 120, 1)\n",
      "X_val shape: (1129, 120, 1)\n",
      "X_test shape: (391, 120, 1)\n",
      "y_train shape: (4513,)\n",
      "y_max: 995\n",
      "max_sequence_length: 120\n",
      "Sample X_train[0] shape: (120, 1)\n",
      "Sample y_train[0]: 0.27638190954773867\n",
      "\n",
      "Classification Class Distribution (Training):\n",
      " 3    713\n",
      "1    710\n",
      "2    710\n",
      "4    696\n",
      "5    609\n",
      "6    606\n",
      "0    469\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Regression RUL Statistics (Training):\n",
      "Mean RUL (normalized): 0.4653034728261293\n",
      "Std RUL (normalized): 0.20160411852453738\n",
      "Min RUL (normalized): 0.10050251256281408\n",
      "Max RUL (normalized): 1.0\n"
     ]
    }
   ],
   "source": [
    "# Load the default configuration\n",
    "config = Config()\n",
    "\n",
    "# Preprocess the dataset for classification (CNN)\n",
    "preprocessed_classification = preprocess_aachen_dataset(\n",
    "    data_path=config.data_path,\n",
    "    test_cell_count=config.test_cell_count,\n",
    "    random_state=config.random_state,\n",
    "    log_transform=config.log_transform,\n",
    "    classification=True  # Explore classification (CNN) output\n",
    ")\n",
    "\n",
    "# Preprocess the dataset for regression (LSTM)\n",
    "preprocessed_regression = preprocess_aachen_dataset(\n",
    "    data_path=config.data_path,\n",
    "    test_cell_count=config.test_cell_count,\n",
    "    random_state=config.random_state,\n",
    "    log_transform=config.log_transform,\n",
    "    classification=False  # Explore regression (LSTM) output\n",
    ")\n",
    "\n",
    "# Explore classification (CNN) output\n",
    "print(\"# Classification (CNN) Output Exploration\")\n",
    "print(\"X_train shape:\", preprocessed_classification[\"X_train\"].shape)  # Expected: (n_samples, 120, 1)\n",
    "print(\"X_val shape:\", preprocessed_classification[\"X_val\"].shape)      # Expected: (n_samples, 120, 1)\n",
    "print(\"X_test shape:\", preprocessed_classification[\"X_test\"].shape)    # Expected: (n_samples, 120, 1)\n",
    "print(\"y_train shape:\", preprocessed_classification[\"y_train\"].shape)  # Expected: (n_samples, 7) for one-hot encoding\n",
    "print(\"y_max:\", preprocessed_classification[\"y_max\"])                 # Maximum RUL for scaling\n",
    "print(\"label_mapping:\", preprocessed_classification[\"label_mapping\"])  # RUL bin mappings\n",
    "print(\"max_sequence_length:\", preprocessed_classification[\"max_sequence_length\"])  # Should be 120 for classification\n",
    "print(\"Sample X_train[0]:\\n\", preprocessed_classification[\"X_train\"][0])  # First sequence\n",
    "print(\"Sample y_train[0]:\\n\", preprocessed_classification[\"y_train\"][0])  # First one-hot label\n",
    "\n",
    "# Explore regression (LSTM) output\n",
    "print(\"\\n# Regression (LSTM) Output Exploration\")\n",
    "print(\"X_train shape:\", preprocessed_regression[\"X_train\"].shape)     # Expected: (n_samples, max_seq_len, 1)\n",
    "print(\"X_val shape:\", preprocessed_regression[\"X_val\"].shape)         # Expected: (n_samples, max_seq_len, 1)\n",
    "print(\"X_test shape:\", preprocessed_regression[\"X_test\"].shape)       # Expected: (n_samples, max_seq_len, 1)\n",
    "print(\"y_train shape:\", preprocessed_regression[\"y_train\"].shape)     # Expected: (n_samples,)\n",
    "print(\"y_max:\", preprocessed_regression[\"y_max\"])                     # Maximum RUL for scaling\n",
    "print(\"max_sequence_length:\", preprocessed_regression[\"max_sequence_length\"])  # Maximum sequence length\n",
    "print(\"Sample X_train[0] shape:\", preprocessed_regression[\"X_train\"][0].shape)  # First sequence dimensions\n",
    "print(\"Sample y_train[0]:\", preprocessed_regression[\"y_train\"][0])     # First normalized RUL\n",
    "\n",
    "# Additional exploration: Class distribution for classification (if applicable)\n",
    "if preprocessed_classification[\"label_mapping\"]:\n",
    "    y_train_classes = np.argmax(preprocessed_classification[\"y_train\"], axis=1)\n",
    "    print(\"\\nClassification Class Distribution (Training):\\n\", pd.Series(y_train_classes).value_counts())\n",
    "\n",
    "# Additional exploration: RUL statistics for regression\n",
    "print(\"\\nRegression RUL Statistics (Training):\")\n",
    "print(\"Mean RUL (normalized):\", np.mean(preprocessed_regression[\"y_train\"]))\n",
    "print(\"Std RUL (normalized):\", np.std(preprocessed_regression[\"y_train\"]))\n",
    "print(\"Min RUL (normalized):\", np.min(preprocessed_regression[\"y_train\"]))\n",
    "print(\"Max RUL (normalized):\", np.max(preprocessed_regression[\"y_train\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import load_preprocessed_data, build_lstm_model, train_lstm_model\n",
    "from src.evaluation import evaluate_lstm_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 11:49:02,701 - INFO - Loaded preprocessed data for regression with EOL 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 11:49:02,808 - INFO - LSTM model built for regression with config: Config(data_path='data/raw/Degradation_Prediction_Dataset_ISEA.mat', eol_capacity=0.65, test_cell_count=3, random_state=42, log_transform=False, classification=False, seq_len=120, train_split_ratio=0.8, val_split_ratio=0.2, lstm_units=32, dropout_rate=0.2, dense_units=16, learning_rate=0.001, clipnorm=1.0, patience=15, batch_size=32, epochs=50)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Build and train the LSTM model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m build_lstm_model((metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_sequence_length\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m1\u001b[39m), config)\n\u001b[0;32m---> 15\u001b[0m history \u001b[38;5;241m=\u001b[39m train_lstm_model(model, X_train, y_train, X_val, y_val, config)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m test_loss, test_mae \u001b[38;5;241m=\u001b[39m evaluate_lstm_model(model, X_test, y_test, metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_max\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Student/Master kode/Master_Herstad-Gjerdingen/src/models.py:125\u001b[0m, in \u001b[0;36mtrain_lstm_model\u001b[0;34m(model, X_train, y_train, X_val, y_val, config)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_lstm_model\u001b[39m(model: tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel, X_train: np\u001b[38;5;241m.\u001b[39mndarray, y_train: np\u001b[38;5;241m.\u001b[39mndarray, X_val: np\u001b[38;5;241m.\u001b[39mndarray, y_val: np\u001b[38;5;241m.\u001b[39mndarray, config: Config) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[1;32m    108\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    Trains the LSTM model for RUL regression with early stopping and model checkpointing.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m        Dict: Training history.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    123\u001b[0m         EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpatience, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m    124\u001b[0m         ModelCheckpoint(\n\u001b[0;32m--> 125\u001b[0m             os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiments\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm_regression_eol\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(config\u001b[38;5;241m.\u001b[39meol_capacity\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    126\u001b[0m             monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    127\u001b[0m             save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    128\u001b[0m             verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    129\u001b[0m         )\n\u001b[1;32m    130\u001b[0m     ]\n\u001b[1;32m    131\u001b[0m     history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    132\u001b[0m         X_train, y_train,\n\u001b[1;32m    133\u001b[0m         validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks\n\u001b[1;32m    138\u001b[0m     )\n\u001b[1;32m    139\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM model trained successfully with config: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(config))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "# Add thesis_experiment/ to sys.path for imports (running from thesis_experiment/)\n",
    "sys.path.append(os.path.abspath(os.getcwd()))\n",
    "\n",
    "# Load configuration\n",
    "config = Config()\n",
    "model_type = \"regression\"  # Fixed for LSTM regression\n",
    "\n",
    "# Load preprocessed data\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, metadata = load_preprocessed_data(\n",
    "    model_type, config.eol_capacity\n",
    ")\n",
    "\n",
    "# Build and train the LSTM model\n",
    "model = build_lstm_model((metadata[\"max_sequence_length\"], 1), config)\n",
    "history = train_lstm_model(model, X_train, y_train, X_val, y_val, config)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_mae = evaluate_lstm_model(model, X_test, y_test, metadata[\"y_max\"])\n",
    "\n",
    "# Print training and evaluation results for verification\n",
    "print(\"Training completed successfully!\")\n",
    "print(f\"Training Loss: {history['loss'][-1]:.4f}\")\n",
    "print(f\"Validation Loss: {history['val_loss'][-1]:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test MAE (rescaled): {test_mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (D2D_env)",
   "language": "python",
   "name": "d2d_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
