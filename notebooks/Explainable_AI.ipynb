{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable AI Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Change to the root directory of the project\n",
    "module_path = os.path.abspath('..')\n",
    "if module_path not in sys.path:\n",
    "    %cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/johannesherstad/miniconda3/envs/D2D_env/lib/python311.zip',\n",
       " '/Users/johannesherstad/miniconda3/envs/D2D_env/lib/python3.11',\n",
       " '/Users/johannesherstad/miniconda3/envs/D2D_env/lib/python3.11/lib-dynload',\n",
       " '',\n",
       " '/Users/johannesherstad/miniconda3/envs/D2D_env/lib/python3.11/site-packages',\n",
       " '/Users/johannesherstad/miniconda3/envs/D2D_env/lib/python3.11/site-packages/setuptools/_vendor',\n",
       " '/Users/johannesherstad']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import load_preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "# \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from src.models import load_preprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretable Alternative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ante-Hoc Explainability Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TimeSHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grad-CAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative XAI Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will evaluate the performance of the different XAI methods on the regression and classification tasks.\n",
    "\n",
    "We will use the following metrics:\n",
    "* Faithfulness\n",
    "    * PGI (Prediction-Guided Importance)\n",
    "    * PGU (Prediction-Guided Unimportance)\n",
    "*\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faithfulness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faithfulness is the degree to which the explanation is faithful to the model. It is measured by the correlation between the explanation and the model's prediction.\n",
    "\n",
    "Through the metrics PGI (Prediction-Guided Importance) and PGU (Prediction-Guided Unimportance), we can measure the faithfulness of the explanation, by perturbing the timesteps deemed most and least important by the XAI methods, and measuring the change in the prediction.\n",
    "\n",
    "The intuition is that if the XAI method is faithful, perturbing the timesteps deemed most important should have a greater impact on the prediction than perturbing the timesteps deemed least important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the most important timesteps from the results of the Explainable AI techniques.\n",
    "# The result for each technique is a sorted list, containing the indices of the most important timesteps from least to most important.\n",
    "\n",
    "# LSTM SHAP\n",
    "\n",
    "# LSTM TimeSHAP\n",
    "\n",
    "# 1D-CNN SHAP\n",
    "\n",
    "# 1D-CNN TimeSHAP\n",
    "\n",
    "# 1D-CNN GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation function\n",
    "\n",
    "def perturbation_function(x, feature_importance_indices):\n",
    "    # Recieve a list of indices of either the most or the least important timesteps\n",
    "    # Perturb the values of these timesteps by adding noise to them\n",
    "    # Return the perturbed input\n",
    "\n",
    "    x_perturbed = x.copy()\n",
    "    for idx in feature_importance_indices:\n",
    "        noise = np.random.normal(loc=0, scale=0.1)\n",
    "        x_perturbed[idx] = x_perturbed[idx] + noise\n",
    "    return x_perturbed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGI AND PGU calculation function\n",
    "\n",
    "def compute_pgi_pgu(model, x, importance_scores, K, runs=10):\n",
    "    # Compute the PGI and PGU scores for the input x\n",
    "    # K is the number of timesteps to perturb\n",
    "    # Runs is the number of times to run the perturbation, to get a more stable estimate\n",
    "    # Return the PGI and PGU scores\n",
    "\n",
    "    pgi_scores = []\n",
    "    pgu_scores = []\n",
    "    for i in range(runs):\n",
    "        # Get the indices of the most important timesteps\n",
    "        feature_importance_indices = importance_scores[:K]\n",
    "\n",
    "        # Perturb the input for the most important timesteps\n",
    "        x_perturbed_PGI = perturbation_function(x, feature_importance_indices)\n",
    "\n",
    "        # Perturb the input for the least important timesteps\n",
    "        x_perturbed_PGU = perturbation_function(x, feature_importance_indices[::-1])\n",
    "\n",
    "        # Get the prediction for the original input\n",
    "        original_prediction = model.predict(x)\n",
    "\n",
    "        # Get the prediction for the perturbed input for the most important timesteps\n",
    "        prediction_PGI = model.predict(x_perturbed_PGI)\n",
    "\n",
    "        # Get the prediction for the perturbed input for the least important timesteps\n",
    "        prediction_PGU = model.predict(x_perturbed_PGU)\n",
    "\n",
    "        # Compute the PGI and PGU scores\n",
    "        pgi = np.linalg.norm(original_prediction - prediction_PGI)\n",
    "        pgu = np.linalg.norm(original_prediction - prediction_PGU)\n",
    "\n",
    "        pgi_scores.append(pgi)\n",
    "        pgu_scores.append(pgu)\n",
    "\n",
    "    return np.mean(pgi_scores), np.mean(pgu_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "D2D_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
